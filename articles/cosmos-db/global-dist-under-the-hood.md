---
title: Distribuzione globale con Azure Cosmos DB - informazioni sul funzionamento
description: In questo articolo vengono forniti i dettagli tecnici relativi alla distribuzione globale di Azure Cosmos DB
author: SnehaGunda
ms.service: cosmos-db
ms.topic: conceptual
ms.date: 12/02/2019
ms.author: sngun
ms.reviewer: sngun
ms.openlocfilehash: a46a69476a2ad6550bc7b3a533fd09565d461db3
ms.sourcegitcommit: 2ec4b3d0bad7dc0071400c2a2264399e4fe34897
ms.translationtype: MT
ms.contentlocale: it-IT
ms.lasthandoff: 03/27/2020
ms.locfileid: "74872129"
---
# <a name="global-data-distribution-with-azure-cosmos-db---under-the-hood"></a>Distribuzione globale dei dati con Azure Cosmos DB - informazioni sul funzionamento

Azure Cosmos DB è un servizio di base in Azure, pertanto viene distribuito in tutte le aree di Azure in tutto il mondo, inclusi i cloud pubblici, sovrani, del Dipartimento della Difesa (DoD) e del governo. All'interno di un data center, distribuiamo e gestiamo Azure Cosmos DB su moltissimi tipi di computer, ognuno con risorse di archiviazione locali dedicate. All'interno di un data center, Azure Cosmos DB viene distribuito tra vari cluster, ognuno dei quali esegue potenzialmente più generazioni di hardware. I computer all'interno di un cluster sono in genere distribuiti tra 10-20 domini di errore per la disponibilità elevata all'interno di un'area. L'immagine seguente mostra la topologia del sistema di distribuzione globale di Cosmos DB:

![Topologia del sistema](./media/global-dist-under-the-hood/distributed-system-topology.png)

**La distribuzione globale in Azure Cosmos DB è chiavi in base alle chiavi in base alle chiavi in base aquanto inversione di livello:Global distribution in Azure Cosmos DB is** In qualsiasi momento, con pochi clic o a livello di codice con una singola chiamata API, è possibile aggiungere o rimuovere le aree geografiche associate al database Cosmos. Un database Cosmos, a sua volta, è costituito da un insieme di contenitori Cosmos. In Cosmos DB, i contenitori fungono da unità logiche di distribuzione e scalabilità. Le raccolte, le tabelle e i grafici che vengono creati sono (internamente) solo contenitori Cosmos. I contenitori sono completamente indipendenti da schema e forniscono un ambito per una query. I dati in un contenitore Cosmos vengono indicizzati automaticamente al momento dell'inserimento. L'indicizzazione automatica consente agli utenti di eseguire query sui dati senza i noglidi della gestione dello schema o dell'indice, in particolare in un'installazione distribuita a livello globale.  

- In una determinata area, i dati all'interno di un contenitore vengono distribuiti utilizzando una chiave di partizione, che è disponibile e gestita in modo trasparente dalle partizioni fisiche sottostanti (*distribuzione locale*).  

- Ogni partizione fisica viene replicata anche tra aree geografiche *(distribuzione globale*). 

Quando un'app che usa Cosmos DB scala in modo elastico la velocità effettiva in un contenitore Cosmos o utilizza più spazio di archiviazione, Cosmos DB gestisce in modo trasparente le operazioni di gestione delle partizioni (split, clone, delete) in tutte le aree. Indipendente da scalabilità, distribuzione o errori, Cosmos DB continua a fornire una singola immagine del sistema dei dati all'interno dei contenitori, che vengono distribuiti globalmente in un grande numero di aree.  

Come illustrato nell'immagine seguente, i dati all'interno di un contenitore vengono distribuiti lungo due dimensioni: all'interno di un'area e tra aree, in tutto il mondo:As shown in the following image, the data within a container is distributed along two dimensions - within a region and across regions, worldwide:  

![partizioni fisiche](./media/global-dist-under-the-hood/distribution-of-resource-partitions.png)

Una partizione fisica viene implementata da un gruppo di repliche, denominato *set di repliche*. Ogni computer ospita centinaia di repliche che corrispondono a varie partizioni fisiche all'interno di un set fisso di processi, come illustrato nell'immagine precedente. Le repliche corrispondenti alle partizioni fisiche vengono posizionate in modo dinamico e con carico bilanciato nei computer all'interno di un cluster e nei data center all'interno di un'area.  

Una replica appartiene in modo univoco a un tenant di Azure Cosmos DB. Ogni replica ospita un'istanza del [motore di database](https://www.vldb.org/pvldb/vol8/p1668-shukla.pdf) di Cosmos DB, che gestisce le risorse, nonché gli indici associati. Il motore di database Cosmos opera su un sistema di tipi basato su atom-record-sequence (ARS). Il motore è agnostico al concetto di schema, sfocando il limite tra la struttura e i valori di istanza dei record. Cosmos DB consente di ottenere la completa indipendenza dallo schema attraverso un'efficiente indicizzazione automatica di tutti gli elementi dopo all'inserimento, consentendo agli utenti di eseguire una query dei dati distribuiti a livello globale senza dover gestire schemi o indici.

Il motore di database Cosmos è costituito da componenti, tra cui l'implementazione di diverse primitive di coordinamento, runtime del linguaggio, il processore di query e i sottosistemi di archiviazione e indicizzazione responsabili dell'archiviazione transazionale e dell'indicizzazione dei dati, Rispettivamente. Per garantire durabilità e disponibilità elevata, il motore di database conserva i dati e l'indice nelle unità SSD e ne esegue la replica, rispettivamente tra le istanze del motore di database all'interno dei set di repliche. I tenant più grandi corrispondono a una maggiore scala di velocità effettiva e archiviazione e dispongono di repliche più grandi o più o di entrambe. Ogni componente del sistema è completamente asincrono: nessun thread si blocca mai e ognuno esegue operazioni di breve durata senza incorrere in eventuali opzioni di thread non necessarie. Limitazione di frequenza e congestione sono sottoposte a plumbing nell'intero stack dal controllo di ammissione a tutti i percorsi I/O. Il motore di database Cosmos è progettato per sfruttare la concorrenza granulare e per offrire una velocità effettiva elevata mentre si opera in quantità frugali di risorse di sistema.

La distribuzione globale di Cosmos DB si basa su due astrazioni chiave: *set di repliche* e set di *partizioni*. Un set di repliche è un "mattoncino" modulare per il coordinamento e un set di partizioni è una sovrapposizione dinamica di una o più partizioni fisiche distribuite geograficamente. Per comprendere il funzionamento della distribuzione globale, è necessario comprendere queste due chiavi di astrazioni. 

## <a name="replica-sets"></a>Set di repliche

Una partizione fisica viene materializzata come un gruppo di repliche con bilanciamento del carico autogestito e dinamico su più domini di errore, denominato set di repliche. Questo set implementa collettivamente il protocollo replicato dello stato del computer per rendere i dati all'interno della partizione fisica altamente disponibili, durevoli e coerenti. L'appartenenza al set di repliche *N* è dinamica, che continua a fluttuare tra *NMin* e *NMax* in base agli errori, alle operazioni amministrative e al tempo di rigenerazione/ripristino delle repliche non riuscite. In base alle modifiche dell'appartenenza, anche il protocollo della replica riconfigura anche le dimensioni del quorum di lettura e scrittura. Per distribuire uniformemente la velocità effettiva assegnata a una determinata partizione fisica, vengono impiegate due idee:To uniformly distribute the throughput that is assigned to a given physical partition, we employ two ideas: 

- In primo luogo, il costo di elaborazione delle richieste di scrittura sul leader è superiore al costo di applicazione degli aggiornamenti sul follower. Di conseguenza, il leader ha in bilancio più risorse di sistema rispetto ai follower. 

- In secondo luogo, per quanto possibile, il quorum di lettura per un livello di coerenza specifico è costituito esclusivamente dalle repliche dei follower. A meno che non necessario, sarà possibile evitare di contattare il leader per la gestione delle operazioni di lettura. Ci avvaliamo di una serie di idee della ricerca condotta sul rapporto di [carico e capacità](https://www.cs.utexas.edu/~lorenzo/corsi/cs395t/04S/notes/naor98load.pdf) nei sistemi basati sul quorum per i cinque modelli di [coerenza](consistency-levels.md) supportati da Cosmos DB.  

## <a name="partition-sets"></a>Set di partizioni

Un gruppo di partizioni fisiche, una per ognuna delle aree del database Cosmos configurate, è composto per gestire lo stesso set di chiavi replicate in tutte le aree configurate. Questa primitiva di coordinamento superiore è denominata *set di partizioni,* ovvero una sovrapposizione dinamica distribuita geograficamente di partizioni fisiche che gestiscono un determinato set di chiavi. Mentre l'ambito di una determinata partizione fisica (un set di repliche) è compreso nell'ambito di un cluster, un set di partizioni può estendersi su cluster, data center e aree geografiche, come illustrato nell'immagine seguente:While a given physical partition (a replica-set) is scoped within a cluster, a partition-set can span clusters, data centers, and geographical regions as shown in the image below:  

![Set di partizioni](./media/global-dist-under-the-hood/dynamic-overlay-of-resource-partitions.png)

È possibile considerare un set di partizioni come un "super set di repliche" geograficamente disperso, composto da più set di repliche che dispongono dello stesso numero di chiavi. Analogamente a un set di repliche, anche l'appartenenza di un set di partizioni è dinamica: fluttua in base alle operazioni implicite di gestione delle partizioni fisiche per aggiungere/rimuovere nuove partizioni da/da un set di partizioni specificato (ad esempio, quando si esegue la scalabilità orizzontale in un contenitore, si aggiunge/rimuove un'area nel database Cosmos o quando si verificano errori). In virtù di avere ciascuna delle partizioni (di un set di partizioni) gestire l'appartenenza del set di partizioni all'interno del proprio set di repliche, l'appartenenza è completamente decentralizzata e a disponibilità elevata. Durante la riconfigurazione di un set di partizioni, viene specificata anche la topologia della sovrapposizione tra le partizioni fisiche. La topologia viene selezionata dinamicamente in base al livello di coerenza, alla distanza geografica e alla larghezza di banda di rete disponibile tra le partizioni fisiche di origine e di destinazione.  

Il servizio consente di configurare i database Cosmos con una singola area di scrittura o con più aree di scrittura e, a seconda della selezione, i set di partizioni sono configurati per accettare le scritture esattamente in una o tutte le aree. Il sistema usa un protocollo di consenso annidato e a due livelli: un livello opera all'interno delle repliche di un set di repliche di una partizione fisica accettando le scritture; l'altro opera a livello di un set di partizioni per fornire garanzie di ordinamento complete per tutte scritture sulle quali è stato eseguito il commit all'interno del set di partizioni. Questo consenso, annidato e a più livelli, è fondamentale per l'implementazione dei rigorosi contratti di servizio per la disponibilità elevata, nonché per l'implementazione di modelli di coerenza offerti ai client da Cosmos DB.  

## <a name="conflict-resolution"></a>Risoluzione dei conflitti

La progettazione per la propagazione degli aggiornamenti, la risoluzione dei conflitti e il rilevamento della causalità sono ispirate al lavoro preliminare sugli [algoritmi epidemici](https://www.cs.utexas.edu/~lorenzo/corsi/cs395t/04S/notes/naor98load.pdf) e il sistema [Bayou](https://zoo.cs.yale.edu/classes/cs422/2013/bib/terry95managing.pdf). Mentre i kernel delle idee rimasti forniscono un pratico riferimento per la comunicazione relativa alla progettazione di sistema di Cosmos DB, sono stati anche sottoposti a una significativa trasformazione una volta applicati al sistema di Cosmos DB. Ciò era necessario, perché i sistemi precedenti non erano stati progettati né con la governance delle risorse né con la scala a cui Cosmos DB deve operare, né per fornire le capacità (ad esempio, coerenza di sbandata delimitata) e la rigorosa e contratti di servizio completi che Cosmos DB offre ai propri clienti.  

È importante ricordare che un set di partizioni viene distribuito tra più aree e segue il protocollo di replica Cosmos DB (multimaster) per replicare i dati tra le partizioni fisiche che comprendono uno specifico set di partizioni. Ogni partizione fisica (di un set di partizioni) in genere accetta le scritture e gestisce le letture dei client locali di una determinata area. Le scritture accettate da una partizione fisica all'interno di un'area vengono memorizzate in modo duraturo e rese altamente disponibili all'interno della partizione fisica prima di essere confermate al client. Si tratta di operazioni di scrittura provvisorie e vengono propagate alle altre partizioni fisiche all'interno del set di partizioni usando un canale antientropia. I client possono richiedere operazioni di scrittura provvisori o sulle quali è stato eseguito il commit, passando un'intestazione di richiesta. La propagazione antientropia (inclusa la frequenza della propagazione) è dinamica e basata sulla topologia del set di partizioni, la prossimità dell'area delle partizioni fisiche e il livello di coerenza configurato. All'interno di un set di partizioni, Cosmos DB segue uno schema di commit primario con una partizione arbiter selezionata dinamicamente. La selezione arbiter è dinamica ed è parte integrante della riconfigurazione del set di partizioni basata sulla topologia della sovrimpressione. Le operazioni di scrittura (inclusi multi-row/in batch gli aggiornamenti) in cui è stato eseguito il commit sono garantite per essere ordinate. 

Vengono usati orologi con vettori codificati (contenenti l'ID dell'area e la logica dell'orologio corrispondente a ogni livello di consenso rispettivamente, al set di repliche e al set di partizioni) per il rilevamento della causalità e della versione vettori per identificare e risolvere conflitti di aggiornamento. La topologia e l'algoritmo di selezione peer sono progettati per garantire risorse di archiviazione predefinite e minime e un sovraccarico di rete minimo dei vettori della versione. L'algoritmo garantisce la rigida proprietà di convergenza.  

Per i database Cosmos configurati con più aree di scrittura, il sistema offre agli sviluppatori una serie di criteri di risoluzione dei conflitti automatica e flessibile, che include: 

- **Last-Write-Wins (LWW)**, che, per impostazione predefinita, utilizza una proprietà timestamp definita dal sistema (basata sul protocollo di clock di sincronizzazione dell'ora). Cosmos DB consente anche di specificare qualsiasi altra proprietà numerica personalizzata da usare per la risoluzione dei conflitti.  
- Criteri di **risoluzione dei conflitti definiti dall'applicazione (personalizzati)** (espressi tramite procedure di unione), progettati per la riconciliazione semantica dei conflitti da parte dell'applicazione. Queste procedure vengono richiamate quando viene rilevato un conflitto tra scrittura e scrittura a cura di una transazione di database, sul lato server. Il sistema fornisce esattamente una garanzia per l'esecuzione di una procedura di unione come parte del protocollo di impegno. Sono disponibili diversi esempi di risoluzione dei [conflitti](how-to-manage-conflicts.md) con cui giocare.  

## <a name="consistency-models"></a>Modelli di coerenza

Sia che si configuri il database Cosmos con una o più aree di scrittura, è possibile scegliere tra i cinque modelli di coerenza ben definiti. Con più aree di scrittura, di seguito sono riportati alcuni aspetti importanti dei livelli di coerenza:With multiple write regions, the following are a few notable aspects of the consistency levels:  

La coerenza di stantio delimitata garantisce che tutte le letture saranno all'interno di prefissi *K* o *T* secondi dall'ultima scrittura in una qualsiasi delle regioni. Inoltre, le letture con coerenza di stantio delimitata sono garantite per essere monotono e con garanzie di prefisso coerenti. Il protocollo antientropia è soggetto a limitazioni di frequenza e assicura che i prefissi non vengono accumulati e che non venga applicata la congestione nelle operazioni di scrittura. La coerenza della sessione garantisce la lettura monotonica, la scrittura monotonica, la lettura delle scritture, la lettura che segue la lettura e garanzie di prefisso coerenti, in tutto il mondo. Per i database configurati con coerenza elevata, i vantaggi (bassa latenza di scrittura, disponibilità elevata di scrittura) di più aree di scrittura non sono applicabili, a causa della replica sincrona tra aree.

La semantica dei cinque modelli di coerenza in Cosmos DB è descritta [qui](consistency-levels.md)e matematicamente descritta utilizzando le specifiche TLA di alto livello [qui](https://github.com/Azure/azure-cosmos-tla).

## <a name="next-steps"></a>Passaggi successivi

Scoprire come configurare la distribuzione globale utilizzando i seguenti articoli:

* [Aggiungere o rimuovere aree dall'account di database](how-to-manage-database-account.md#addremove-regions-from-your-database-account)
* [Come configurare i client per il multihoming](how-to-manage-database-account.md#configure-multiple-write-regions)
* [Come creare criteri di risoluzione dei conflitti personalizzatiHow to create a custom conflict resolution policy](how-to-manage-conflicts.md#create-a-custom-conflict-resolution-policy)
