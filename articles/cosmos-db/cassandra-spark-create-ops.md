---
title: Creare o inserire dati in Azure Cosmos DB API Cassandra da Spark
description: Questo articolo illustra in dettaglio come inserire dati di esempio nelle tabelle dell'API Cassandra di Azure Cosmos DB
author: kanshiG
ms.author: govindk
ms.reviewer: sngun
ms.service: cosmos-db
ms.subservice: cosmosdb-cassandra
ms.topic: how-to
ms.date: 09/24/2018
ms.openlocfilehash: 3ec44d20b763a98683d9b947c94ad6be75180113
ms.sourcegitcommit: 3bdeb546890a740384a8ef383cf915e84bd7e91e
ms.translationtype: MT
ms.contentlocale: it-IT
ms.lasthandoff: 10/30/2020
ms.locfileid: "93092254"
---
# <a name="createinsert-data-into-azure-cosmos-db-cassandra-api-from-spark"></a>Creare/inserire dati nell'API Cassandra di Azure Cosmos DB da Spark
[!INCLUDE[appliesto-cassandra-api](includes/appliesto-cassandra-api.md)]
 
Questo articolo descrive come inserire dati di esempio in una tabella nell'API Cassandra di Azure Cosmos DB da Spark.

## <a name="cassandra-api-configuration"></a>Configurazione dell'API Cassandra

```scala
import org.apache.spark.sql.cassandra._
//Spark connector
import com.datastax.spark.connector._
import com.datastax.spark.connector.cql.CassandraConnector

//CosmosDB library for multiple retry
import com.microsoft.azure.cosmosdb.cassandra

//Connection-related
spark.conf.set("spark.cassandra.connection.host","YOUR_ACCOUNT_NAME.cassandra.cosmosdb.azure.com")
spark.conf.set("spark.cassandra.connection.port","10350")
spark.conf.set("spark.cassandra.connection.ssl.enabled","true")
spark.conf.set("spark.cassandra.auth.username","YOUR_ACCOUNT_NAME")
spark.conf.set("spark.cassandra.auth.password","YOUR_ACCOUNT_KEY")
spark.conf.set("spark.cassandra.connection.factory", "com.microsoft.azure.cosmosdb.cassandra.CosmosDbConnectionFactory")
//Throughput-related...adjust as needed
spark.conf.set("spark.cassandra.output.batch.size.rows", "1")
spark.conf.set("spark.cassandra.connection.connections_per_executor_max", "10")
spark.conf.set("spark.cassandra.output.concurrent.writes", "1000")
spark.conf.set("spark.cassandra.concurrent.reads", "512")
spark.conf.set("spark.cassandra.output.batch.grouping.buffer.size", "1000")
spark.conf.set("spark.cassandra.connection.keep_alive_ms", "600000000")
```
## <a name="dataframe-api"></a>API dataframe

### <a name="create-a-dataframe-with-sample-data"></a>Creare un frame di dati con dati di esempio

```scala
// Generate a dataframe containing five records
val booksDF = Seq(
   ("b00001", "Arthur Conan Doyle", "A study in scarlet", 1887),
   ("b00023", "Arthur Conan Doyle", "A sign of four", 1890),
   ("b01001", "Arthur Conan Doyle", "The adventures of Sherlock Holmes", 1892),
   ("b00501", "Arthur Conan Doyle", "The memoirs of Sherlock Holmes", 1893),
   ("b00300", "Arthur Conan Doyle", "The hounds of Baskerville", 1901)
).toDF("book_id", "book_author", "book_name", "book_pub_year")

//Review schema
booksDF.printSchema

//Print
booksDF.show
```

> [!NOTE]
> La funzionalità "Crea se non esiste", a livello di riga, non è ancora supportata.

### <a name="persist-to-azure-cosmos-db-cassandra-api"></a>Salvare i dati nell'API Cassandra di Azure Cosmos DB

Durante il salvataggio dei dati, è anche possibile specificare le impostazioni di durata e dei criteri di coerenza come illustrato nell'esempio seguente:

```scala
//Persist
booksDF.write
  .mode("append")
  .format("org.apache.spark.sql.cassandra")
  .options(Map( "table" -> "books", "keyspace" -> "books_ks", "output.consistency.level" -> "ALL", "ttl" -> "10000000"))
  .save()
```

> [!NOTE]
> La durata (TTL) a livello di colonna non è ancora supportata.

#### <a name="validate-in-cqlsh"></a>Convalidare in cqlsh

```sql
use books_ks;
select * from books;
```

## <a name="resilient-distributed-database-rdd-api"></a>API RDD (Resilient Distributed Database)

### <a name="create-a-rdd-with-sample-data"></a>Creare un database RDD con dati di esempio
```scala
//Delete records created in the previous section 
val cdbConnector = CassandraConnector(sc)
cdbConnector.withSessionDo(session => session.execute("delete from books_ks.books where book_id in ('b00300','b00001','b00023','b00501','b09999','b01001','b00999','b03999','b02999');"))

//Create RDD
val booksRDD = sc.parallelize(Seq(
   ("b00001", "Arthur Conan Doyle", "A study in scarlet", 1887),
   ("b00023", "Arthur Conan Doyle", "A sign of four", 1890),
   ("b01001", "Arthur Conan Doyle", "The adventures of Sherlock Holmes", 1892),
   ("b00501", "Arthur Conan Doyle", "The memoirs of Sherlock Holmes", 1893),
   ("b00300", "Arthur Conan Doyle", "The hounds of Baskerville", 1901)
))

//Review
booksRDD.take(2).foreach(println)
```

> [!NOTE]
> La funzionalità "Crea se non esiste" non è ancora supportata.

### <a name="persist-to-azure-cosmos-db-cassandra-api"></a>Salvare i dati nell'API Cassandra di Azure Cosmos DB

Durante il salvataggio dei dati nell'API Cassandra, è anche possibile specificare le impostazioni di durata e dei criteri di coerenza come illustrato nell'esempio seguente:

```scala
import com.datastax.spark.connector.writer._

//Persist
booksRDD.saveToCassandra("books_ks", "books", SomeColumns("book_id", "book_author", "book_name", "book_pub_year"),writeConf = WriteConf(ttl = TTLOption.constant(900000),consistencyLevel = ConsistencyLevel.ALL))
```

#### <a name="validate-in-cqlsh"></a>Convalidare in cqlsh

```sql
use books_ks;
select * from books;
```

## <a name="next-steps"></a>Passaggi successivi

Dopo aver inserito i dati nella tabella dell'API Cassandra di Azure Cosmos DB, passare agli articoli seguenti per eseguire altre operazioni sui dati archiviati nell'API Cassandra di Azure Cosmos DB:
 
* [Operazioni di lettura](cassandra-spark-read-ops.md)
* [Operazioni di upsert](cassandra-spark-upsert-ops.md)
* [Operazioni Delete](cassandra-spark-delete-ops.md)
* [Operazioni di aggregazione](cassandra-spark-aggregation-ops.md)
* [Operazioni di copia di tabelle](cassandra-spark-table-copy-ops.md)

